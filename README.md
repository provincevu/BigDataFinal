# ğŸ›’ RETAIL BIG DATA PIPELINE

## Há»‡ Thá»‘ng PhÃ¢n TÃ­ch Dá»¯ Liá»‡u BÃ¡n Láº» Sá»­ Dá»¥ng CÃ´ng Nghá»‡ Big Data

---

## ğŸ“‹ Má»¤C Lá»¤C

1. [Tá»•ng Quan Dá»± Ãn](#-tá»•ng-quan-dá»±-Ã¡n)
2. [Kiáº¿n TrÃºc Há»‡ Thá»‘ng](#-kiáº¿n-trÃºc-há»‡-thá»‘ng)
3. [CÃ´ng Nghá»‡ Sá»­ Dá»¥ng](#-cÃ´ng-nghá»‡-sá»­-dá»¥ng)
4. [YÃªu Cáº§u Há»‡ Thá»‘ng](#-yÃªu-cáº§u-há»‡-thá»‘ng)
5. [HÆ°á»›ng Dáº«n CÃ i Äáº·t](#-hÆ°á»›ng-dáº«n-cÃ i-Ä‘áº·t)
6. [HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng](#-hÆ°á»›ng-dáº«n-sá»­-dá»¥ng)
7. [MÃ´ Táº£ Dataset](#-mÃ´-táº£-dataset)
8. [CÃ¡c Chá»©c NÄƒng PhÃ¢n TÃ­ch](#-cÃ¡c-chá»©c-nÄƒng-phÃ¢n-tÃ­ch)
9. [Cáº¥u TrÃºc ThÆ° Má»¥c](#-cáº¥u-trÃºc-thÆ°-má»¥c)
10. [Chi Tiáº¿t CÃ¡c File](#-chi-tiáº¿t-cÃ¡c-file)
11. [CÃ¡c Lá»‡nh Há»¯u Ãch](#-cÃ¡c-lá»‡nh-há»¯u-Ã­ch)
12. [Xá»­ LÃ½ Lá»—i ThÆ°á»ng Gáº·p](#-xá»­-lÃ½-lá»—i-thÆ°á»ng-gáº·p)
13. [TÃ i Liá»‡u Tham Kháº£o](#-tÃ i-liá»‡u-tham-kháº£o)

---

## ğŸ¯ Tá»”NG QUAN Dá»° ÃN

### Má»¥c Ä‘Ã­ch

XÃ¢y dá»±ng má»™t **Data Pipeline** hoÃ n chá»‰nh Ä‘á»ƒ phÃ¢n tÃ­ch dá»¯ liá»‡u bÃ¡n láº» cá»§a doanh nghiá»‡p, giÃºp:

- PhÃ¢n tÃ­ch doanh thu theo tá»«ng thá»i Ä‘iá»ƒm (giá», ngÃ y, thÃ¡ng, nÄƒm)
- XÃ¡c Ä‘á»‹nh sáº£n pháº©m bÃ¡n cháº¡y nháº¥t
- PhÃ¢n khÃºc khÃ¡ch hÃ ng theo hÃ nh vi mua sáº¯m
- PhÃ¢n cá»¥m khÃ¡ch hÃ ng cÃ³ hÃ nh vi tÆ°Æ¡ng tá»± (Clustering)
- Dá»± Ä‘oÃ¡n xu hÆ°á»›ng mua hÃ ng

### Äáº·c Ä‘iá»ƒm ná»•i báº­t

- âœ… **Äáº§y Ä‘á»§ stack Big Data**: Hadoop, Hive, Spark, MongoDB
- âœ… **Containerized**: Cháº¡y hoÃ n toÃ n trÃªn Docker, dá»… triá»ƒn khai
- âœ… **Interactive UI**: Hue, Jupyter Notebook, Mongo Express
- âœ… **Real analytics**: RFM Analysis, K-Means Clustering
- âœ… **Visualization**: Biá»ƒu Ä‘á»“ trá»±c quan vá»›i Matplotlib/Seaborn

---

## ğŸ—ï¸ KIáº¾N TRÃšC Há»† THá»NG

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           USER INTERFACE                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Hue:8788   â”‚  â”‚ Jupyter:8889 â”‚  â”‚  HDFS:9870   â”‚  â”‚ Spark:8580   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚                 â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         â”‚          DATA PROCESSING LAYER    â”‚                 â”‚         â”‚
â”‚         â”‚                 â”‚                 â”‚                 â”‚         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Hive Server  â”‚  â”‚ Spark Master â”‚  â”‚   NameNode   â”‚  â”‚ Spark Worker â”‚ â”‚
â”‚  â”‚   :10000     â”‚  â”‚    :7077     â”‚  â”‚    :9000     â”‚  â”‚              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                                   â”‚                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚Hive Metastoreâ”‚                    â”‚   DataNode   â”‚                   â”‚
â”‚  â”‚    :9083     â”‚                    â”‚    :9864     â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         â”‚                   DATA STORAGE LAYER                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚  â”‚  PostgreSQL  â”‚                    â”‚   MongoDB    â”‚                   â”‚
â”‚  â”‚ (Metastore)  â”‚                    â”‚   :27017     â”‚                   â”‚
â”‚  â”‚    :5432     â”‚                    â”‚              â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow (Luá»“ng Dá»¯ Liá»‡u)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw CSV    â”‚ â”€â”€â–¶  â”‚    HDFS     â”‚ â”€â”€â–¶  â”‚   Spark     â”‚
â”‚  (Input)    â”‚      â”‚  (Storage)  â”‚      â”‚ (Processing)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚                            â”‚                        â”‚
                     â–¼                            â–¼                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚    Hive     â”‚             â”‚   MongoDB   â”‚          â”‚   Jupyter   â”‚
              â”‚ (Warehouse) â”‚             â”‚  (NoSQL)    â”‚          â”‚ (Analysis)  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ CÃ”NG NGHá»† Sá»¬ Dá»¤NG

| CÃ´ng nghá»‡                | PhiÃªn báº£n | Vai trÃ²                              |
| ------------------------ | --------- | ------------------------------------ |
| **Apache Hadoop (HDFS)** | 3.2.1     | LÆ°u trá»¯ dá»¯ liá»‡u phÃ¢n tÃ¡n             |
| **Apache Hive**          | 2.3.2     | Data Warehouse, SQL queries          |
| **Apache Spark**         | 3.1.1     | Xá»­ lÃ½ dá»¯ liá»‡u & Machine Learning     |
| **MongoDB**              | 5.0       | NoSQL database cho káº¿t quáº£ phÃ¢n tÃ­ch |
| **PostgreSQL**           | 9.5       | Metastore cho Hive                   |
| **Hue**                  | 4.10.0    | Web GUI cho Hadoop/Hive              |
| **Jupyter Notebook**     | Latest    | Interactive data analysis            |
| **Docker**               | 20.10+    | Container orchestration              |
| **Python**               | 3.9       | Scripting, ML algorithms             |

### ThÆ° viá»‡n Python sá»­ dá»¥ng

- **PySpark**: Xá»­ lÃ½ dá»¯ liá»‡u phÃ¢n tÃ¡n
- **Pandas**: Data manipulation
- **Matplotlib/Seaborn**: Data visualization
- **Scikit-learn**: Machine Learning (K-Means)
- **PyMongo**: Káº¿t ná»‘i MongoDB

---

## ğŸ’» YÃŠU Cáº¦U Há»† THá»NG

### Pháº§n cá»©ng

| YÃªu cáº§u  | Tá»‘i thiá»ƒu   | Khuyáº¿n nghá»‹ |
| -------- | ----------- | ----------- |
| **RAM**  | 8 GB        | 16 GB       |
| **CPU**  | 4 cores     | 8 cores     |
| **Disk** | 20 GB trá»‘ng | 50 GB trá»‘ng |

### Pháº§n má»m

- **Docker Desktop** (Windows/Mac) hoáº·c Docker Engine (Linux)
- **Docker Compose** v2.0+
- **Git** (optional)

### Há»‡ Ä‘iá»u hÃ nh há»— trá»£

- âœ… Windows 10/11 (vá»›i WSL2)
- âœ… macOS 10.15+
- âœ… Ubuntu 20.04+
- âœ… CentOS 7+

---

## ğŸš€ HÆ¯á»šNG DáºªN CÃ€I Äáº¶T

### BÆ°á»›c 1: Chuáº©n bá»‹ thÆ° má»¥c

```powershell
# Di chuyá»ƒn Ä‘áº¿n thÆ° má»¥c project
cd D:\BigDataFinal
```

### BÆ°á»›c 2: Äáº£m báº£o cÃ³ file dá»¯ liá»‡u

Äáº£m báº£o file `online_retail.csv` náº±m trong thÆ° má»¥c `D:\BigDataFinal\`

### BÆ°á»›c 3: Khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng

**Windows (PowerShell):**

```powershell
# CÃ¡ch 1: Sá»­ dá»¥ng script
.\start.bat

# CÃ¡ch 2: Docker Compose trá»±c tiáº¿p
docker-compose up -d
```

**Linux/Mac:**

```bash
chmod +x start.sh
./start.sh
```

### BÆ°á»›c 4: Kiá»ƒm tra services

```powershell
# Xem tráº¡ng thÃ¡i cÃ¡c container
docker-compose ps

# Táº¥t cáº£ services pháº£i á»Ÿ tráº¡ng thÃ¡i "Up"
```

### BÆ°á»›c 5: Chá» khá»Ÿi Ä‘á»™ng hoÃ n táº¥t

â±ï¸ Láº§n Ä‘áº§u tiÃªn cÃ³ thá»ƒ máº¥t **3-5 phÃºt** Ä‘á»ƒ download images vÃ  khá»Ÿi Ä‘á»™ng.

Kiá»ƒm tra logs:

```powershell
docker-compose logs -f hive-metastore
# Chá» tháº¥y: "Starting hive metastore on port 9083"
```

---

## ğŸ“– HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG

### ğŸ¯ CÃ¡ch 1: Sá»­ Dá»¥ng Jupyter Notebook (Äá» xuáº¥t - Nhanh nháº¥t)

1. **Má»Ÿ trÃ¬nh duyá»‡t**: http://localhost:8889
2. **Nháº­p token**: `bigdata2024`
3. **Má»Ÿ notebook**: `simple_retail_analysis.ipynb`
4. **Cháº¡y táº¥t cáº£ cells**: Menu â†’ Run â†’ Run All Cells
5. **Xem káº¿t quáº£**: Biá»ƒu Ä‘á»“ hiá»ƒn thá»‹ trá»±c tiáº¿p trong notebook

### ğŸ¯ CÃ¡ch 2: Cháº¡y Spark ETL Pipeline

```powershell
# BÆ°á»›c 1: Upload dá»¯ liá»‡u lÃªn HDFS
.\upload-data.bat

# BÆ°á»›c 2: Cháº¡y ETL Pipeline
.\run-etl.bat

# BÆ°á»›c 3: Cháº¡y Customer Clustering
.\run-clustering.bat
```

### ğŸ¯ CÃ¡ch 3: Sá»­ Dá»¥ng Hue (SQL Queries)

1. **Má»Ÿ trÃ¬nh duyá»‡t**: http://localhost:8788
2. **Táº¡o tÃ i khoáº£n**: Láº§n Ä‘áº§u tá»± táº¡o (admin/admin)
3. **VÃ o Query Editor**: Chá»n Hive
4. **Cháº¡y queries**: Sá»­ dá»¥ng cÃ¡c query trong `hive-queries/retail_analytics.sql`

---

## ğŸ“Š MÃ” Táº¢ DATASET

### Nguá»“n dá»¯ liá»‡u

**Online Retail Dataset** - Dá»¯ liá»‡u giao dá»‹ch thá»±c táº¿ cá»§a má»™t cÃ´ng ty bÃ¡n láº» online cÃ³ trá»¥ sá»Ÿ táº¡i UK.

### ThÃ´ng tin dataset

| Thuá»™c tÃ­nh              | GiÃ¡ trá»‹                 |
| ----------------------- | ----------------------- |
| Sá»‘ báº£n ghi              | 541,909                 |
| Sá»‘ báº£n ghi sau lÃ m sáº¡ch | ~397,884                |
| Thá»i gian               | 01/12/2010 - 09/12/2011 |
| Sá»‘ khÃ¡ch hÃ ng           | ~4,372                  |
| Sá»‘ sáº£n pháº©m             | ~3,958                  |
| Sá»‘ quá»‘c gia             | 38                      |

### Cáº¥u trÃºc cÃ¡c cá»™t

| Cá»™t           | Kiá»ƒu dá»¯ liá»‡u | MÃ´ táº£                                                 | VÃ­ dá»¥                              |
| ------------- | ------------ | ----------------------------------------------------- | ---------------------------------- |
| `InvoiceNo`   | String       | MÃ£ hÃ³a Ä‘Æ¡n (6 chá»¯ sá»‘). Náº¿u báº¯t Ä‘áº§u báº±ng 'C' = Ä‘Æ¡n há»§y | 536365, C536379                    |
| `StockCode`   | String       | MÃ£ sáº£n pháº©m (5 chá»¯ sá»‘)                                | 85123A                             |
| `Description` | String       | TÃªn/mÃ´ táº£ sáº£n pháº©m                                    | WHITE HANGING HEART T-LIGHT HOLDER |
| `Quantity`    | Integer      | Sá»‘ lÆ°á»£ng mua                                          | 6                                  |
| `InvoiceDate` | Timestamp    | NgÃ y giá» giao dá»‹ch                                    | 2010-12-01 08:26:00                |
| `UnitPrice`   | Double       | ÄÆ¡n giÃ¡ (Â£)                                           | 2.55                               |
| `CustomerID`  | Integer      | MÃ£ khÃ¡ch hÃ ng (5 chá»¯ sá»‘)                              | 17850                              |
| `Country`     | String       | Quá»‘c gia cá»§a khÃ¡ch hÃ ng                               | United Kingdom                     |

### Xá»­ lÃ½ dá»¯ liá»‡u (Data Cleaning)

Pipeline tá»± Ä‘á»™ng loáº¡i bá»:

- âŒ Báº£n ghi thiáº¿u CustomerID
- âŒ Quantity <= 0 (sáº£n pháº©m tráº£ láº¡i)
- âŒ UnitPrice <= 0
- âŒ InvoiceNo báº¯t Ä‘áº§u báº±ng 'C' (Ä‘Æ¡n hÃ ng há»§y)

---

## ğŸ“ˆ CÃC CHá»¨C NÄ‚NG PHÃ‚N TÃCH

### 1. ğŸ“Š PhÃ¢n TÃ­ch Doanh Thu Theo Thá»i Gian

| PhÃ¢n tÃ­ch            | MÃ´ táº£                                    | Output      |
| -------------------- | ---------------------------------------- | ----------- |
| Theo thÃ¡ng           | Doanh thu tá»«ng thÃ¡ng, xu hÆ°á»›ng tÄƒng/giáº£m | Bar chart   |
| Theo ngÃ y trong tuáº§n | NgÃ y nÃ o bÃ¡n Ä‘Æ°á»£c nhiá»u nháº¥t             | Bar chart   |
| Theo giá»             | Giá» cao Ä‘iá»ƒm bÃ¡n hÃ ng                    | Line chart  |
| Theo quÃ½             | So sÃ¡nh doanh thu cÃ¡c quÃ½                | Stacked bar |

**Insight máº«u**: ThÃ¡ng 11 cÃ³ doanh thu cao nháº¥t do mua sáº¯m cuá»‘i nÄƒm.

### 2. ğŸ† PhÃ¢n TÃ­ch Sáº£n Pháº©m BÃ¡n Cháº¡y

| PhÃ¢n tÃ­ch             | MÃ´ táº£                                  |
| --------------------- | -------------------------------------- |
| Top 15 theo doanh thu | Sáº£n pháº©m Ä‘Ã³ng gÃ³p doanh thu cao nháº¥t   |
| Top 10 theo sá»‘ lÆ°á»£ng  | Sáº£n pháº©m bÃ¡n Ä‘Æ°á»£c nhiá»u nháº¥t           |
| Top theo sá»‘ Ä‘Æ¡n hÃ ng  | Sáº£n pháº©m xuáº¥t hiá»‡n nhiá»u Ä‘Æ¡n hÃ ng nháº¥t |

### 3. ğŸ‘¥ PhÃ¢n TÃ­ch RFM (Recency-Frequency-Monetary)

**RFM** lÃ  phÆ°Æ¡ng phÃ¡p phÃ¢n khÃºc khÃ¡ch hÃ ng dá»±a trÃªn 3 yáº¿u tá»‘:

| Yáº¿u tá»‘        | Ã nghÄ©a           | CÃ¡ch tÃ­nh               |
| ------------- | ----------------- | ----------------------- |
| **R**ecency   | Má»›i mua gáº§n Ä‘Ã¢y?  | Sá»‘ ngÃ y tá»« láº§n mua cuá»‘i |
| **F**requency | Mua thÆ°á»ng xuyÃªn? | Sá»‘ láº§n mua hÃ ng         |
| **M**onetary  | Chi tiÃªu nhiá»u?   | Tá»•ng sá»‘ tiá»n Ä‘Ã£ chi     |

**CÃ¡c phÃ¢n khÃºc khÃ¡ch hÃ ng:**

| Segment                   | MÃ´ táº£                | Chiáº¿n lÆ°á»£c                |
| ------------------------- | -------------------- | ------------------------- |
| ğŸ’ **Champions**          | Râ†‘ Fâ†‘ Mâ†‘ - KhÃ¡ch VIP | Giá»¯ chÃ¢n, Æ°u Ä‘Ã£i Ä‘áº·c biá»‡t |
| â¤ï¸ **Loyal Customers**    | Fâ†‘ Mâ†‘                | Upsell, cross-sell        |
| â­ **Potential Loyalist** | Râ†‘ Fâ†“ Mâ†‘             | Khuyáº¿n khÃ­ch mua thÃªm     |
| ğŸ†• **Recent Customers**   | Râ†‘                   | ChÃ o Ä‘Ã³n, giá»›i thiá»‡u SP   |
| âš ï¸ **At Risk**            | Râ†“ Fâ†‘                | Win-back campaign         |
| ğŸ˜´ **Lost**               | Râ†“ Fâ†“ Mâ†“             | Reactivation email        |

### 4. ğŸ¯ PhÃ¢n Cá»¥m KhÃ¡ch HÃ ng (K-Means Clustering)

Sá»­ dá»¥ng thuáº­t toÃ¡n **K-Means** Ä‘á»ƒ nhÃ³m khÃ¡ch hÃ ng cÃ³ hÃ nh vi tÆ°Æ¡ng tá»±:

**Quy trÃ¬nh:**

1. Chuáº©n hÃ³a dá»¯ liá»‡u RFM (StandardScaler)
2. TÃ¬m sá»‘ cluster tá»‘i Æ°u báº±ng Elbow Method
3. Ãp dá»¥ng K-Means vá»›i K=4
4. PhÃ¢n tÃ­ch Ä‘áº·c Ä‘iá»ƒm tá»«ng cluster

**CÃ¡c cluster Ä‘iá»ƒn hÃ¬nh:**

- ğŸ”´ **Cluster 0**: VIP Customers - Chi tiÃªu cao, mua thÆ°á»ng xuyÃªn
- ğŸ”µ **Cluster 1**: Frequent Buyers - Mua nhiá»u láº§n, giÃ¡ trá»‹ trung bÃ¬nh
- ğŸŸ¢ **Cluster 2**: Regular Customers - KhÃ¡ch hÃ ng bÃ¬nh thÆ°á»ng
- ğŸŸ¡ **Cluster 3**: Inactive Customers - ÄÃ£ lÃ¢u khÃ´ng mua

### 5. ğŸŒ PhÃ¢n TÃ­ch Theo Äá»‹a LÃ½

- Doanh thu theo quá»‘c gia
- Sá»‘ khÃ¡ch hÃ ng theo vÃ¹ng
- Thá»‹ trÆ°á»ng tiá»m nÄƒng ngoÃ i UK

---

## ğŸ“ Cáº¤U TRÃšC THÆ¯ Má»¤C

```
BigDataFinal/
â”‚
â”œâ”€â”€ ğŸ“„ docker-compose.yml      # Cáº¥u hÃ¬nh Docker orchestration
â”œâ”€â”€ ğŸ“„ online_retail.csv       # Dataset gá»‘c
â”œâ”€â”€ ğŸ“„ README.md               # TÃ i liá»‡u nÃ y
â”œâ”€â”€ ğŸ“„ HUONG_DAN_SU_DUNG.md    # HÆ°á»›ng dáº«n tiáº¿ng Viá»‡t
â”œâ”€â”€ ğŸ“„ README_UI.md            # HÆ°á»›ng dáº«n sá»­ dá»¥ng Web UI
â”‚
â”œâ”€â”€ ğŸ“ config/                 # Cáº¥u hÃ¬nh cÃ¡c services
â”‚   â”œâ”€â”€ hadoop.env             # Biáº¿n mÃ´i trÆ°á»ng Hadoop
â”‚   â”œâ”€â”€ hive-site.xml          # Cáº¥u hÃ¬nh Hive
â”‚   â””â”€â”€ hue.ini                # Cáº¥u hÃ¬nh Hue
â”‚
â”œâ”€â”€ ğŸ“ spark-apps/             # CÃ¡c á»©ng dá»¥ng Spark
â”‚   â”œâ”€â”€ retail_etl_pipeline.py # ETL Pipeline chÃ­nh
â”‚   â”œâ”€â”€ customer_clustering.py # PhÃ¢n cá»¥m K-Means
â”‚   â””â”€â”€ product_recommendation.py # Há»‡ thá»‘ng gá»£i Ã½
â”‚
â”œâ”€â”€ ğŸ“ notebooks/              # Jupyter Notebooks
â”‚   â”œâ”€â”€ retail_analysis.ipynb  # PhÃ¢n tÃ­ch vá»›i Spark
â”‚   â””â”€â”€ simple_retail_analysis.ipynb # PhÃ¢n tÃ­ch vá»›i Pandas
â”‚
â”œâ”€â”€ ğŸ“ hive-queries/           # SQL queries cho Hive
â”‚   â””â”€â”€ retail_analytics.sql   # CÃ¡c query phÃ¢n tÃ­ch
â”‚
â”œâ”€â”€ ğŸ“ mongo-init/             # Khá»Ÿi táº¡o MongoDB
â”‚   â””â”€â”€ init-mongo.js          # Script táº¡o collections
â”‚
â”œâ”€â”€ ğŸ“ data/                   # ThÆ° má»¥c dá»¯ liá»‡u (mount vÃ o containers)
â”‚   â””â”€â”€ output/                # Káº¿t quáº£ phÃ¢n tÃ­ch
â”‚
â”œâ”€â”€ ğŸ”§ start.bat / start.sh    # Script khá»Ÿi Ä‘á»™ng
â”œâ”€â”€ ğŸ”§ stop.bat / stop.sh      # Script dá»«ng
â”œâ”€â”€ ğŸ”§ upload-data.bat         # Upload data lÃªn HDFS
â”œâ”€â”€ ğŸ”§ run-etl.bat             # Cháº¡y ETL Pipeline
â””â”€â”€ ğŸ”§ run-clustering.bat      # Cháº¡y Clustering
```

---

## ğŸ“ CHI TIáº¾T CÃC FILE

### docker-compose.yml

Äá»‹nh nghÄ©a 11 services:

| Service              | Image                                     | Ports      | MÃ´ táº£              |
| -------------------- | ----------------------------------------- | ---------- | ------------------ |
| `namenode`           | bde2020/hadoop-namenode:2.0.0-hadoop3.2.1 | 9870, 9000 | HDFS Master        |
| `datanode`           | bde2020/hadoop-datanode:2.0.0-hadoop3.2.1 | 9864       | HDFS Worker        |
| `hive-metastore`     | bde2020/hive:2.3.2-postgresql-metastore   | 9083       | Hive Metadata      |
| `hive-server`        | bde2020/hive:2.3.2-postgresql-metastore   | 10000      | Hive Thrift Server |
| `postgres-metastore` | postgres:9.5                              | 5432       | Metastore DB       |
| `spark-master`       | bde2020/spark-master:3.1.1-hadoop3.2      | 8080, 7077 | Spark Master       |
| `spark-worker`       | bde2020/spark-worker:3.1.1-hadoop3.2      | 8081       | Spark Worker       |
| `mongodb`            | mongo:5.0                                 | 27017      | NoSQL Database     |
| `mongo-express`      | mongo-express:1.0.0-alpha                 | 8082       | MongoDB UI         |
| `hue`                | gethue/hue:4.10.0                         | 8888       | Hadoop Web UI      |
| `jupyter`            | jupyter/pyspark-notebook                  | 8889       | Notebook Server    |

### config/hive-site.xml

Cáº¥u hÃ¬nh quan trá»ng:

- Káº¿t ná»‘i PostgreSQL metastore
- Thrift URI cho remote metastore
- Timeout settings Ä‘á»ƒ trÃ¡nh lá»—i khi xá»­ lÃ½ dá»¯ liá»‡u lá»›n
- Authentication vÃ  transport mode

### spark-apps/retail_etl_pipeline.py

Pipeline ETL gá»“m cÃ¡c bÆ°á»›c:

1. `create_spark_session()` - Khá»Ÿi táº¡o Spark vá»›i Hive & MongoDB
2. `load_and_clean_data()` - Load CSV, lÃ m sáº¡ch dá»¯ liá»‡u
3. `save_to_hdfs()` - LÆ°u vÃ o HDFS dáº¡ng Parquet
4. `create_hive_tables()` - Táº¡o báº£ng trong Hive
5. `analyze_revenue_by_time()` - PhÃ¢n tÃ­ch doanh thu
6. `analyze_top_products()` - Top sáº£n pháº©m
7. `analyze_customer_behavior()` - PhÃ¢n tÃ­ch RFM
8. `save_to_mongodb()` - LÆ°u káº¿t quáº£ vÃ o MongoDB

### notebooks/simple_retail_analysis.ipynb

Notebook phÃ¢n tÃ­ch trá»±c tiáº¿p báº±ng Pandas (khÃ´ng cáº§n Spark):

- Nhanh hÆ¡n, dá»… debug
- Trá»±c quan hÃ³a ngay trong notebook
- PhÃ¹ há»£p cho demo vÃ  há»c táº­p

---

## ğŸŒ TRUY Cáº¬P SERVICES

| Service                 | URL                   | Dang nhap                |
| ----------------------- | --------------------- | ------------------------ |
| :chart_with_upwards_trend: **Jupyter Notebook** | http://localhost:8889 | Token: xem docker logs jupyter |
| :file_folder: **HDFS NameNode**    | http://localhost:9870 | Khong can                |
| :zap: **Spark Master UI**  | http://localhost:8580 | Khong can                |
| :mag: **Hue**              | http://localhost:8788 | Tao lan dau: admin/admin |
| :leaves: **Mongo Express**    | http://localhost:8290 | admin / admin123         |
| :package: **HDFS DataNode**    | http://localhost:9864 | Khong can                |
| :wrench: **Spark Worker**     | http://localhost:8581 | Khong can                |

---

## ğŸ’¡ CÃC Lá»†NH Há»®U ÃCH

### Docker

```powershell
# Khá»Ÿi Ä‘á»™ng táº¥t cáº£ services
docker-compose up -d

# Dá»«ng táº¥t cáº£ services
docker-compose down

# Xem logs cá»§a service cá»¥ thá»ƒ
docker-compose logs -f spark-master

# Restart má»™t service
docker-compose restart hive-server

# VÃ o container
docker exec -it spark-master bash

# Xem tráº¡ng thÃ¡i
docker-compose ps

# XÃ³a hoÃ n toÃ n (bao gá»“m data)
docker-compose down -v
```

### HDFS

```powershell
# Liá»‡t kÃª files
docker exec namenode hdfs dfs -ls /user/retail

# Xem dung lÆ°á»£ng
docker exec namenode hdfs dfs -du -h /user

# Upload file
docker exec namenode hdfs dfs -put /data/file.csv /user/retail/

# Download file
docker exec namenode hdfs dfs -get /user/retail/file.csv /data/

# XÃ³a file
docker exec namenode hdfs dfs -rm -r /user/retail/test
```

### Hive

```powershell
# VÃ o Hive CLI
docker exec -it hive-server hive

# Cháº¡y query
docker exec hive-server hive -e "SHOW DATABASES;"
docker exec hive-server hive -e "USE retail_db; SHOW TABLES;"
docker exec hive-server hive -e "SELECT COUNT(*) FROM retail_db.transactions;"
```

### Spark

```powershell
# Submit job
docker exec spark-master /spark/bin/spark-submit `
    --master spark://spark-master:7077 `
    /spark-apps/retail_etl_pipeline.py

# Spark Shell (Scala)
docker exec -it spark-master /spark/bin/spark-shell

# PySpark Shell
docker exec -it spark-master /spark/bin/pyspark
```

### MongoDB

```powershell
# VÃ o Mongo Shell
docker exec -it mongodb mongosh -u admin -p admin123

# Xem databases
docker exec mongodb mongosh -u admin -p admin123 --eval "show dbs"

# Query collection
docker exec mongodb mongosh -u admin -p admin123 --eval "use retail_analytics; db.customer_segments.find().limit(5)"
```

---

## âš ï¸ Xá»¬ LÃ Lá»–I THÆ¯á»œNG Gáº¶P

### 1. Services khÃ´ng khá»Ÿi Ä‘á»™ng Ä‘Æ°á»£c

```powershell
# Kiá»ƒm tra logs
docker-compose logs

# Restart vá»›i clean state
docker-compose down -v
docker-compose up -d
```

### 2. Hive Metastore khÃ´ng káº¿t ná»‘i

```powershell
# Chá» metastore khá»Ÿi Ä‘á»™ng hoÃ n táº¥t
docker-compose logs hive-metastore

# Restart Hive services
docker-compose restart postgres-metastore hive-metastore hive-server
```

### 3. Spark job fails vá»›i "Out of Memory"

TÄƒng memory trong docker-compose.yml:

```yaml
spark-master:
  environment:
    - SPARK_DRIVER_MEMORY=2g
    - SPARK_EXECUTOR_MEMORY=2g
```

### 4. Jupyter khÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c

```powershell
docker-compose restart jupyter
# Chá» 30 giÃ¢y rá»“i truy cáº­p láº¡i
```

### 5. Lá»—i "hive.metastore.fastpath"

Äáº£m báº£o file `config/hive-site.xml` KHÃ”NG cÃ³ property:

```xml
<!-- ÄÃƒ XÃ“A - KHÃ”NG DÃ™NG PROPERTY NÃ€Y -->
<property>
    <name>hive.metastore.fastpath</name>
    <value>true</value>
</property>
```

### 6. Timeout khi táº¡o Hive tables

Äáº£m báº£o cÃ³ cÃ¡c timeout settings trong `hive-site.xml`:

```xml
<property>
    <name>hive.metastore.client.socket.timeout</name>
    <value>600s</value>
</property>
```

---

## ğŸ“š TÃ€I LIá»†U THAM KHáº¢O

### CÃ´ng nghá»‡

- [Apache Hadoop Documentation](https://hadoop.apache.org/docs/)
- [Apache Hive Documentation](https://cwiki.apache.org/confluence/display/Hive/)
- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [MongoDB Manual](https://www.mongodb.com/docs/manual/)
- [Hue User Guide](https://docs.gethue.com/)

### Thuáº­t toÃ¡n

- [RFM Analysis](<https://en.wikipedia.org/wiki/RFM_(market_research)>)
- [K-Means Clustering](https://scikit-learn.org/stable/modules/clustering.html#k-means)

### Dataset

- [Online Retail Dataset - UCI](https://archive.ics.uci.edu/ml/datasets/online+retail)

---

## ğŸ‘¨â€ğŸ’» TÃC GIáº¢

**Email**: tinhvu2k4@gmail.com

---

## ğŸ“„ LICENSE

MIT License - CÃ³ thá»ƒ sá»­ dá»¥ng cho má»¥c Ä‘Ã­ch há»c táº­p vÃ  nghiÃªn cá»©u.

---

**Last Updated**: December 2025
